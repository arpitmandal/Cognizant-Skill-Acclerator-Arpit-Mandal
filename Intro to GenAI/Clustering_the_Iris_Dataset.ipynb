{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01l0c_jmIXXM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_index\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Implementing Clustering\n",
        "\n",
        "# Step 1: Load the Iris dataset from the provided file\n",
        "print(\"Step 1: Loading the Iris dataset from file...\")\n",
        "\n",
        "# Define column names\n",
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
        "\n",
        "# Load the data\n",
        "iris_df = pd.read_csv('iris.data.txt', header=None, names=column_names)\n",
        "\n",
        "# Create a mapping for class labels to numeric values\n",
        "class_mapping = {\n",
        "    'Iris-setosa': 0,\n",
        "    'Iris-versicolor': 1,\n",
        "    'Iris-virginica': 2\n",
        "}\n",
        "\n",
        "# Create a numeric target column\n",
        "iris_df['class_numeric'] = iris_df['class'].map(class_mapping)\n",
        "\n",
        "# Display information about the dataset\n",
        "print(f\"Dataset Shape: {iris_df.shape}\")\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(iris_df.head())\n",
        "print(\"\\nClass distribution:\")\n",
        "print(iris_df['class'].value_counts())\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(iris_df.describe())"
      ],
      "metadata": {
        "id": "WSqeyRfRI6Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the data\n",
        "print(\"\\nStep 2: Preprocessing the data...\")\n",
        "\n",
        "# Extract features (excluding class labels)\n",
        "X = iris_df.iloc[:, 0:4].values\n",
        "y = iris_df['class_numeric'].values\n",
        "\n",
        "# Normalize/standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Data has been standardized. Mean of each feature is now approximately 0, and standard deviation is 1.\")"
      ],
      "metadata": {
        "id": "zof06IPRI_Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Implement K-means Clustering\n",
        "print(\"\\nStep 3: Implementing K-means Clustering...\")\n",
        "\n",
        "# Finding the optimal number of clusters using the Elbow Method\n",
        "inertia = []\n",
        "k_range = range(1, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Method results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, inertia, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.grid(True)\n",
        "plt.savefig('elbow_method.png')\n",
        "print(\"Elbow Method plot saved as 'elbow_method.png'\")"
      ],
      "metadata": {
        "id": "1zBmTAuWJBaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhouette scores for different k values\n",
        "silhouette_scores = []\n",
        "for k in range(2, 11):  # Silhouette score requires at least 2 clusters\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "    silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "    print(f\"For n_clusters = {k}, the silhouette score is {silhouette_avg:.3f}\")\n",
        "\n",
        "# Plot silhouette scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(2, 11), silhouette_scores, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Different k Values')\n",
        "plt.grid(True)\n",
        "plt.savefig('silhouette_scores.png')\n",
        "print(\"Silhouette Score plot saved as 'silhouette_scores.png'\")"
      ],
      "metadata": {
        "id": "Tuiad580JBjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose optimal k based on analysis (k=3)\n",
        "k_optimal = 3\n",
        "print(f\"\\nChosen optimal number of clusters (k): {k_optimal}\")\n",
        "\n",
        "# Fit K-means with the optimal k\n",
        "kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to the original dataframe\n",
        "iris_df['kmeans_cluster'] = cluster_labels\n",
        "\n",
        "# Display cluster distribution\n",
        "print(\"\\nCluster distribution:\")\n",
        "print(iris_df['kmeans_cluster'].value_counts())"
      ],
      "metadata": {
        "id": "BGUz_5lLJBsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Implement Hierarchical Clustering\n",
        "print(\"\\nStep 4: Implementing Hierarchical Clustering...\")\n",
        "\n",
        "# Compute the linkage matrix\n",
        "Z = linkage(X_scaled, method='ward')\n",
        "\n",
        "# Plot the dendrogram\n",
        "plt.figure(figsize=(12, 8))\n",
        "dendrogram(Z, leaf_rotation=90, leaf_font_size=8)\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Sample index')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y=5, color='r', linestyle='--')  # Suggest a cut-off\n",
        "plt.savefig('dendrogram.png')\n",
        "print(\"Dendrogram saved as 'dendrogram.png'\")"
      ],
      "metadata": {
        "id": "_lCaaId0JBxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Debugging Issues\n",
        "print(\"\\n--- Part 2: Debugging Issues ---\")\n",
        "\n",
        "# Check if the data was properly scaled\n",
        "print(\"\\nChecking for scaling issues...\")\n",
        "if np.abs(X_scaled.mean()) < 0.01 and np.abs(X_scaled.std() - 1) < 0.01:\n",
        "    print(\"Data is properly scaled: Mean is close to 0 and standard deviation is close to 1.\")\n",
        "else:\n",
        "    print(\"WARNING: Data may not be properly scaled!\")\n",
        "    print(f\"Mean: {X_scaled.mean()}\")\n",
        "    print(f\"Standard deviation: {X_scaled.std()}\")\n",
        "\n",
        "# Check for outliers\n",
        "print(\"\\nChecking for outliers...\")\n",
        "z_scores = stats.zscore(X_scaled)\n",
        "abs_z_scores = np.abs(z_scores)\n",
        "outliers = (abs_z_scores > 3).any(axis=1)\n",
        "print(f\"Number of samples with outliers (z-score > 3): {outliers.sum()}\")\n",
        "if outliers.sum() > 0:\n",
        "    print(\"Outlier samples indices:\")\n",
        "    print(np.where(outliers)[0])"
      ],
      "metadata": {
        "id": "NDWG5BFwJL8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different initialization methods for K-means\n",
        "print(\"\\nTesting different initialization methods for K-means...\")\n",
        "init_methods = ['k-means++', 'random']\n",
        "silhouette_init = {}\n",
        "\n",
        "for init in init_methods:\n",
        "    kmeans_init = KMeans(n_clusters=k_optimal, init=init, random_state=42, n_init=10)\n",
        "    cluster_labels_init = kmeans_init.fit_predict(X_scaled)\n",
        "    silhouette_init[init] = silhouette_score(X_scaled, cluster_labels_init)\n",
        "    print(f\"Initialization method: {init}, Silhouette Score: {silhouette_init[init]:.3f}\")\n",
        "\n",
        "best_init = max(silhouette_init, key=silhouette_init.get)\n",
        "print(f\"Best initialization method: {best_init}\")\n",
        "\n",
        "# Use the best initialization method\n",
        "kmeans_best = KMeans(n_clusters=k_optimal, init=best_init, random_state=42, n_init=10)\n",
        "cluster_labels_best = kmeans_best.fit_predict(X_scaled)\n",
        "iris_df['best_cluster'] = cluster_labels_best"
      ],
      "metadata": {
        "id": "E9BYiRHwJMCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Evaluating the Model\n",
        "print(\"\\n--- Part 3: Evaluating the Model ---\")\n",
        "\n",
        "# Visualize clusters in 2D using PCA\n",
        "print(\"\\nVisualizing clusters using PCA...\")\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Ground truth classes\n",
        "plt.subplot(2, 2, 1)\n",
        "for i in range(3):\n",
        "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], label=f'Class {i} ({list(class_mapping.keys())[i]})')\n",
        "plt.title('PCA of Iris dataset - Ground Truth Classes')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.legend()\n",
        "\n",
        "# K-means clusters\n",
        "plt.subplot(2, 2, 2)\n",
        "for i in range(k_optimal):\n",
        "    plt.scatter(X_pca[cluster_labels_best == i, 0], X_pca[cluster_labels_best == i, 1], label=f'Cluster {i}')\n",
        "plt.title('PCA of Iris dataset - K-means Clusters')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.legend()\n",
        "\n",
        "# Sepal length vs width\n",
        "plt.subplot(2, 2, 3)\n",
        "for i in range(3):\n",
        "    plt.scatter(X[y == i, 0], X[y == i, 1], label=f'Class {i} ({list(class_mapping.keys())[i]})')\n",
        "plt.title('Sepal Length vs Sepal Width - Ground Truth')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Sepal Width')\n",
        "plt.legend()\n",
        "\n",
        "# Petal length vs width\n",
        "plt.subplot(2, 2, 4)\n",
        "for i in range(3):\n",
        "    plt.scatter(X[y == i, 2], X[y == i, 3], label=f'Class {i} ({list(class_mapping.keys())[i]})')\n",
        "plt.title('Petal Length vs Petal Width - Ground Truth')\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Petal Width')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('cluster_visualization.png')\n",
        "print(\"Cluster visualization saved as 'cluster_visualization.png'\")"
      ],
      "metadata": {
        "id": "FqVOV9XVJMH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate clustering against ground truth\n",
        "print(\"\\nEvaluating clustering against ground truth...\")\n",
        "ari = adjusted_rand_index(y, cluster_labels_best)\n",
        "print(f\"Adjusted Rand Index: {ari:.3f}\")\n",
        "print(\"Note: ARI ranges from -1 to 1, where 1 indicates perfect agreement, and values around 0 indicate random labeling.\")\n",
        "\n",
        "# Contingency table\n",
        "contingency_table = pd.crosstab(\n",
        "    iris_df['class_numeric'],\n",
        "    iris_df['best_cluster'],\n",
        "    rownames=['Class'],\n",
        "    colnames=['Cluster']\n",
        ")\n",
        "print(\"\\nContingency table (Clusters vs. Classes):\")\n",
        "print(contingency_table)\n",
        "\n",
        "# Map clusters to classes\n",
        "cluster_to_class_mapping = {}\n",
        "for cluster in range(k_optimal):\n",
        "    most_common_class = contingency_table[cluster].idxmax()\n",
        "    cluster_to_class_mapping[cluster] = most_common_class\n",
        "\n",
        "print(\"\\nMapping clusters to original classes:\")\n",
        "for cluster, class_num in cluster_to_class_mapping.items():\n",
        "    class_name = list(class_mapping.keys())[class_num]\n",
        "    print(f\"Cluster {cluster} → Class {class_num} ({class_name})\")\n",
        "\n",
        "# Overall agreement\n",
        "mapped_labels = np.array([cluster_to_class_mapping[label] for label in cluster_labels_best])\n",
        "agreement = np.sum(mapped_labels == y) / len(y)\n",
        "print(f\"\\nOverall agreement after mapping: {agreement:.3f} or {agreement*100:.1f}%\")"
      ],
      "metadata": {
        "id": "bUUXzA5BJMM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3D visualization of the clusters\n",
        "print(\"\\nCreating 3D visualization of clusters...\")\n",
        "\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Choose 3 features for visualization\n",
        "features_to_plot = [0, 2, 3]  # sepal_length, petal_length, petal_width\n",
        "feature_names = [column_names[i] for i in features_to_plot]\n",
        "\n",
        "for cluster in range(k_optimal):\n",
        "    indices = cluster_labels_best == cluster\n",
        "    ax.scatter(\n",
        "        X[indices, features_to_plot[0]],\n",
        "        X[indices, features_to_plot[1]],\n",
        "        X[indices, features_to_plot[2]],\n",
        "        label=f'Cluster {cluster} → {list(class_mapping.keys())[cluster_to_class_mapping[cluster]]}'\n",
        "    )\n",
        "\n",
        "ax.set_xlabel(feature_names[0])\n",
        "ax.set_ylabel(feature_names[1])\n",
        "ax.set_zlabel(feature_names[2])\n",
        "ax.set_title('3D Visualization of Iris Clusters')\n",
        "plt.legend()\n",
        "plt.savefig('iris_clusters_3d.png')\n",
        "print(\"3D visualization saved as 'iris_clusters_3d.png'\")"
      ],
      "metadata": {
        "id": "Y2sCSVqzJMSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pair plot for all features\n",
        "print(\"\\nCreating pair plot for feature relationships...\")\n",
        "\n",
        "iris_df_with_clusters = iris_df.copy()\n",
        "iris_df_with_clusters['species'] = iris_df_with_clusters['class']\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "pair_plot = sns.pairplot(\n",
        "    iris_df_with_clusters,\n",
        "    vars=column_names[:4],\n",
        "    hue='species',\n",
        "    diag_kind='kde',\n",
        "    plot_kws={'alpha': 0.6}\n",
        ")\n",
        "pair_plot.fig.suptitle('Pair Plot of Iris Features by Species', y=1.02, fontsize=16)\n",
        "plt.savefig('iris_pair_plot.png')\n",
        "print(\"Pair plot saved as 'iris_pair_plot.png'\")"
      ],
      "metadata": {
        "id": "7iyWiRaJJMW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Silhouette analysis visualization\n",
        "print(\"\\nPerforming silhouette analysis visualization...\")\n",
        "from sklearn.metrics import silhouette_samples\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "silhouette_vals = silhouette_samples(X_scaled, cluster_labels_best)\n",
        "\n",
        "y_lower, y_upper = 0, 0\n",
        "yticks = []\n",
        "\n",
        "for i, cluster in enumerate(range(k_optimal)):\n",
        "    cluster_silhouette_vals = silhouette_vals[cluster_labels_best == cluster]\n",
        "    cluster_silhouette_vals.sort()\n",
        "    y_upper += len(cluster_silhouette_vals)\n",
        "    color = plt.cm.nipy_spectral(float(i) / k_optimal)\n",
        "    plt.barh(range(y_lower, y_upper), cluster_silhouette_vals, height=1.0,\n",
        "            edgecolor='none', color=color)\n",
        "    yticks.append((y_lower + y_upper) / 2)\n",
        "    y_lower += len(cluster_silhouette_vals)\n",
        "\n",
        "silhouette_avg = silhouette_score(X_scaled, cluster_labels_best)\n",
        "plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "plt.yticks(yticks, [f'Cluster {i}' for i in range(k_optimal)])\n",
        "plt.xlabel('Silhouette Coefficient')\n",
        "plt.ylabel('Cluster')\n",
        "plt.title(f'Silhouette Analysis (Average Score: {silhouette_avg:.3f})')\n",
        "plt.savefig('silhouette_analysis.png')\n",
        "print(\"Silhouette analysis visualization saved as 'silhouette_analysis.png'\")"
      ],
      "metadata": {
        "id": "5GyeGQUbJtke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance based on cluster centers\n",
        "print(\"\\nAnalyzing feature importance based on cluster centers...\")\n",
        "feature_names = column_names[:4]\n",
        "cluster_centers = kmeans_best.cluster_centers_\n",
        "\n",
        "print(\"\\nCluster Centers (in scaled space):\")\n",
        "centers_df = pd.DataFrame(cluster_centers, columns=feature_names)\n",
        "centers_df.index = [f'Cluster {i}' for i in range(k_optimal)]\n",
        "print(centers_df)\n",
        "\n",
        "# Prediction function\n",
        "print(\"\\nCreating a function to predict clusters for new iris measurements...\")\n",
        "def predict_iris_cluster(sepal_length, sepal_width, petal_length, petal_width):\n",
        "    \"\"\"\n",
        "    Predict the cluster for a new iris flower based on its measurements.\n",
        "    \"\"\"\n",
        "    features = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "    features_scaled = scaler.transform(features)\n",
        "    cluster = kmeans_best.predict(features_scaled)[0]\n",
        "    class_idx = cluster_to_class_mapping[cluster]\n",
        "    species = list(class_mapping.keys())[class_idx]\n",
        "    return cluster, species\n",
        "\n",
        "# Example predictions\n",
        "print(\"\\nExample predictions:\")\n",
        "sample1 = predict_iris_cluster(5.1, 3.5, 1.4, 0.2)  # Likely setosa\n",
        "sample2 = predict_iris_cluster(6.3, 3.3, 6.0, 2.5)  # Likely virginica\n",
        "sample3 = predict_iris_cluster(5.7, 2.8, 4.1, 1.3)  # Likely versicolor\n",
        "\n",
        "print(f\"Sample 1: Cluster {sample1[0]}, Likely species: {sample1[1]}\")\n",
        "print(f\"Sample 2: Cluster {sample2[0]}, Likely species: {sample2[1]}\")\n",
        "print(f\"Sample 3: Cluster {sample3[0]}, Likely species: {sample3[1]}\")\n",
        "\n",
        "print(\"\\nClustering analysis complete!\")"
      ],
      "metadata": {
        "id": "QD0zu-9kJw-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}