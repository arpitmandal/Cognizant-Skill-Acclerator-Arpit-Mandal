{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voPntFb0KLTN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support, roc_curve, auc\n",
        "\n",
        "# Deep learning and text processing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Building and Optimizing a CNN for Binary Classification\n",
        "print(\"Part 1: Building and Optimizing a CNN for Spam Classification\")\n",
        "print(\"\\nStep 1: Loading and preprocessing the data...\")\n",
        "\n",
        "# Load the spam dataset\n",
        "df = pd.read_csv('spam.csv', encoding='cp1252')\n",
        "\n",
        "# Rename columns\n",
        "df = df.rename(columns={'v1': 'label', 'v2': 'message'})\n",
        "\n",
        "# Keep only the needed columns\n",
        "df = df[['label', 'message']]\n",
        "\n",
        "# Map labels to numeric values (ham=0, spam=1)\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Display dataset information\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# Calculate spam percentage\n",
        "spam_percentage = df['label'].mean() * 100\n",
        "print(f\"Spam percentage: {spam_percentage:.2f}%\")\n",
        "\n",
        "print(\"\\nDisplay a few examples:\")\n",
        "for i in range(5):\n",
        "    label = \"SPAM\" if df.iloc[i]['label'] == 1 else \"HAM\"\n",
        "    print(f\"{label}: {df.iloc[i]['message'][:80]}...\")"
      ],
      "metadata": {
        "id": "RlBlEHaboWjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing function\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and normalize text data\"\"\"\n",
        "    text = text.lower()\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply text preprocessing\n",
        "df['clean_message'] = df['message'].apply(clean_text)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_message'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "FIh1O_k-oWmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "max_features = 5000  # Maximum number of words to keep\n",
        "max_len = 100        # Maximum sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Get vocabulary size\n",
        "vocab_size = min(max_features, len(tokenizer.word_index) + 1)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "print(f\"Padded training data shape: {X_train_pad.shape}\")\n",
        "print(f\"Padded testing data shape: {X_test_pad.shape}\")"
      ],
      "metadata": {
        "id": "DggsTwimoWpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStep 2: Building the CNN model...\")\n",
        "\n",
        "# CNN model architecture\n",
        "def create_cnn_model(vocab_size, embedding_dim=100, max_len=100, filters=128, kernel_size=5, dropout_rate=0.3):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
        "        Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "embedding_dim = 100\n",
        "cnn_model = create_cnn_model(vocab_size, embedding_dim, max_len)\n",
        "\n",
        "# Display model summary\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "LFU6tREcoWvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStep 3: Training the model...\")\n",
        "\n",
        "# Set up callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_spam_cnn_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = cnn_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "hp7KAdEboWyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStep 4: Evaluating the model...\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = cnn_model.evaluate(X_test_pad, y_test, verbose=1)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = cnn_model.predict(X_test_pad)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calculate metrics\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "AoDuNJeHoW10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Debugging Model Failures\n",
        "print(\"\\nPart 2: Debugging Model Issues\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png')\n",
        "print(\"Training history plot saved as 'training_history.png'\")"
      ],
      "metadata": {
        "id": "fZc88vsEoW5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for overfitting\n",
        "train_acc = history.history['accuracy'][-1]\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "accuracy_diff = train_acc - val_acc\n",
        "\n",
        "print(\"\\nChecking for overfitting:\")\n",
        "print(f\"Final training accuracy: {train_acc:.4f}\")\n",
        "print(f\"Final validation accuracy: {val_acc:.4f}\")\n",
        "print(f\"Difference: {accuracy_diff:.4f}\")\n",
        "\n",
        "if accuracy_diff > 0.05:\n",
        "    print(\"Potential overfitting detected\")\n",
        "\n",
        "    print(\"\\nApplying solutions to overfitting:\")\n",
        "    from tensorflow.keras.regularizers import l2\n",
        "\n",
        "    def create_regularized_model(vocab_size, embedding_dim=100, max_len=100, dropout_rate=0.5):\n",
        "        model = Sequential([\n",
        "            Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
        "            Conv1D(filters=64, kernel_size=5, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "            GlobalMaxPooling1D(),\n",
        "            Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "            Dropout(dropout_rate),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    # Create and train regularized model\n",
        "    regularized_model = create_regularized_model(vocab_size, embedding_dim, max_len)\n",
        "    regularized_history = regularized_model.fit(\n",
        "        X_train_pad, y_train,\n",
        "        epochs=15,\n",
        "        batch_size=64,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate regularized model\n",
        "    reg_test_loss, reg_test_accuracy = regularized_model.evaluate(X_test_pad, y_test, verbose=1)\n",
        "    print(f\"\\nRegularized model test accuracy: {reg_test_accuracy:.4f}\")\n",
        "\n",
        "    y_pred_proba_reg = regularized_model.predict(X_test_pad)\n",
        "    y_pred_reg = (y_pred_proba_reg > 0.5).astype(int).flatten()\n",
        "\n",
        "    print(\"\\nRegularized Model Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_reg))\n",
        "\n",
        "    # Model comparison\n",
        "    print(\"\\nModel comparison:\")\n",
        "    print(f\"Original model accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Regularized model accuracy: {reg_test_accuracy:.4f}\")\n",
        "\n",
        "    if reg_test_accuracy > test_accuracy:\n",
        "        print(\"Using the regularized model for further analysis\")\n",
        "        best_model = regularized_model\n",
        "        y_pred = y_pred_reg\n",
        "        y_pred_proba = y_pred_proba_reg\n",
        "    else:\n",
        "        print(\"Using the original model for further analysis\")\n",
        "        best_model = cnn_model\n",
        "else:\n",
        "    print(\"No significant overfitting detected\")\n",
        "    best_model = cnn_model"
      ],
      "metadata": {
        "id": "QQsd4QDLoW8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Evaluating Model Effectiveness\n",
        "print(\"\\nPart 3: Evaluating Model Effectiveness\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Ham', 'Spam'],\n",
        "            yticklabels=['Ham', 'Spam'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "print(\"Confusion matrix plot saved as 'confusion_matrix.png'\")"
      ],
      "metadata": {
        "id": "UIou9XQ3oW_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('roc_curve.png')\n",
        "print(\"ROC curve plot saved as 'roc_curve.png'\")"
      ],
      "metadata": {
        "id": "3uEz6F2RoXDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze misclassified examples\n",
        "y_pred_binary = best_model.predict(X_test_pad) > 0.5\n",
        "misclassified_indices = np.where(y_pred_binary.flatten() != y_test)[0]\n",
        "\n",
        "print(f\"\\nNumber of misclassified examples: {len(misclassified_indices)}\")\n",
        "\n",
        "if len(misclassified_indices) > 0:\n",
        "    print(\"\\nAnalyzing misclassified examples:\")\n",
        "    X_test_array = np.array(X_test)\n",
        "\n",
        "    def classify_error(true_label, pred_proba):\n",
        "        if true_label == 1 and pred_proba < 0.5:\n",
        "            return \"False Negative (Spam missed)\"\n",
        "        else:\n",
        "            return \"False Positive (Ham marked as spam)\"\n",
        "\n",
        "    num_to_show = min(5, len(misclassified_indices))\n",
        "    for i in range(num_to_show):\n",
        "        idx = misclassified_indices[i]\n",
        "        true_label = y_test.iloc[idx]\n",
        "        pred_proba = y_pred_proba[idx][0]\n",
        "        error_type = classify_error(true_label, pred_proba)\n",
        "\n",
        "        print(f\"\\nExample {i+1} - {error_type}:\")\n",
        "        print(f\"Message: {X_test_array[idx][:100]}...\")\n",
        "        print(f\"True label: {'Spam' if true_label == 1 else 'Ham'}\")\n",
        "        print(f\"Predicted probability: {pred_proba:.4f}\")"
      ],
      "metadata": {
        "id": "YAROBujLoXGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict_spam(message, model, tokenizer, max_len=100):\n",
        "    \"\"\"\n",
        "    Predict if a message is spam using the trained model.\n",
        "    \"\"\"\n",
        "    cleaned_message = clean_text(message)\n",
        "    sequence = tokenizer.texts_to_sequences([cleaned_message])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
        "    prediction = model.predict(padded_sequence)[0][0]\n",
        "    return ('SPAM' if prediction > 0.5 else 'HAM', prediction)\n",
        "\n",
        "# Test with example messages\n",
        "example_messages = [\n",
        "    \"Congratulations! You've won a free iPhone. Click here to claim now!\",\n",
        "    \"Hey, what time are we meeting for dinner tonight?\",\n",
        "    \"URGENT: Your bank account has been compromised. Reply with your details immediately.\",\n",
        "    \"Don't forget to pick up milk on your way home.\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting the spam prediction function:\")\n",
        "for message in example_messages:\n",
        "    label, probability = predict_spam(message, best_model, tokenizer)\n",
        "    print(f\"\\nMessage: {message}\")\n",
        "    print(f\"Prediction: {label} (Probability: {probability:.4f})\")\n",
        "\n",
        "print(\"\\nSpam classification project complete!\")"
      ],
      "metadata": {
        "id": "U57o5wlgoXJy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}